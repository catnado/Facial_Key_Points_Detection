{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(123)  # for reproducibility\n",
    " \n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, LeakyReLU, PReLU, LocallyConnected2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy.ndimage import rotate\n",
    "\n",
    "from random import uniform\n",
    "from numpy.random import choice\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from randomized_relu import randomized_relu\n",
    "from drop_activation import drop_activation\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "get_custom_objects().update({'randomized_relu': Activation(randomized_relu)})\n",
    "get_custom_objects().update({'drop_activation': Activation(drop_activation)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mirror functions\n",
    "def mirror_X(input_X):\n",
    "    return input_X.reshape(-1,96,96)[:, :, list(range(95, -1, -1))].reshape(-1, 96*96)\n",
    "    \n",
    "def mirror_y(input_y, n_point):\n",
    "    output_y = input_y.copy()\n",
    "    # y coordinate stays the same, x coordinate is 96-x\n",
    "    output_y[:,list(range(0,n_point-1,2))] = 95 - input_y[:,list(range(0,n_point-1,2))]\n",
    "    return output_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mirror function to transform X\n",
    "def rotate_X(input_X, degree):\n",
    "    \n",
    "    # create an array of the same size\n",
    "    output_X = np.zeros((input_X.shape), dtype=np.float64)\n",
    "    \n",
    "    # for each image, use sklearn's rotate function to rotate image\n",
    "    # this somehow changes pixel values, cap value between 0 and 255\n",
    "    for i in range(output_X.shape[0]):\n",
    "        output_X[i] = np.clip(rotate(input_X.reshape(-1,96,96)[i], degree, reshape=False, mode='constant', \\\n",
    "                                       cval=150).reshape(96*96), 0, 255)  \n",
    "    return output_X\n",
    "        \n",
    "    \n",
    "# mirror function to transform y\n",
    "def rotate_y(input_y, degree, n_point):\n",
    "    \n",
    "    # create an array of same size\n",
    "    output_y = np.zeros((input_y.shape), dtype=np.float64)\n",
    "    \n",
    "    # define rotation angle and center of rotation\n",
    "    theta = np.radians(degree)\n",
    "    center_x = 95/2\n",
    "    center_y = 95/2\n",
    "\n",
    "    for i in range(output_y.shape[0]):\n",
    "        \n",
    "        # obtain x and y coordinates from dataset\n",
    "        x = input_y[i][np.arange(0,n_point-1,2)]\n",
    "        y = input_y[i][np.arange(1,n_point,2)]\n",
    "        \n",
    "        # use rotation matrix to rotate coordinates around center\n",
    "        x2 = np.cos(theta) * (x - center_x) + np.sin(theta) * (y - center_y) + center_x\n",
    "        y2 = -np.sin(theta) * (x - center_x) + np.cos(theta) * (y - center_y) + center_y\n",
    "        \n",
    "        # put x and y back in original shape\n",
    "        output_y[i] = np.vstack((x2,y2)).transpose().flatten()\n",
    "        \n",
    "    return output_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function - only need to transform X\n",
    "def reduce_contrast(input_X, weight):\n",
    "    return (weight * input_X) + (1 - weight) * input_X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data\n",
    "def prep_data(X, y, points, val_pct):\n",
    "    \n",
    "    # model with specific points \n",
    "    y_model = y[:, points]\n",
    "\n",
    "    # get index of non-missing labels\n",
    "    index = ~np.isnan(y_model).any(axis=1)\n",
    "\n",
    "    # filter out missing labels on training and validation data\n",
    "    X_model = X[index]\n",
    "    y_model = y_model[index]\n",
    "    \n",
    "    # create training and validation set (80/20 split)\n",
    "    X_train, X_val = X_model[:int(X_model.shape[0]*(1-val_pct))], X_model[int(X_model.shape[0]*(1-val_pct)):]\n",
    "    y_train, y_val = y_model[:int(X_model.shape[0]*(1-val_pct))], y_model[int(X_model.shape[0]*(1-val_pct)):]\n",
    "\n",
    "    # training data transformation\n",
    "    degree1 = -10\n",
    "    degree2 = 10\n",
    "    n_point = len(points)\n",
    "    percent = 0.9\n",
    "\n",
    "    X_rotated = np.zeros((X_train.shape), dtype=np.float64)\n",
    "    X_rotated[range(0, len(X_train), 2)] = rotate_X(X_train[range(0, len(X_train), 2)], degree1)\n",
    "    X_rotated[range(1, len(X_train), 2)] = rotate_X(X_train[range(1, len(X_train), 2)], degree2)\n",
    "\n",
    "    y_rotated = np.zeros((y_train.shape), dtype=np.float64)\n",
    "    y_rotated[range(0, len(y_train), 2)] = rotate_y(y_train[range(0, len(y_train), 2)], degree1, n_point)\n",
    "    y_rotated[range(1, len(y_train), 2)] = rotate_y(y_train[range(1, len(y_train), 2)], degree2, n_point)   \n",
    "\n",
    "    X_rotated = np.concatenate((X_train, X_rotated), axis=0)\n",
    "    y_rotated = np.concatenate((y_train, y_rotated), axis=0)\n",
    "    \n",
    "    X_contrast = X_rotated.copy()\n",
    "    X_contrast[range(1, len(X_rotated), 2)] = reduce_contrast(X_rotated[range(1, len(X_rotated), 2)], percent)\n",
    "    \n",
    "    return X_contrast.reshape(-1,96,96,1), y_rotated, X_val.reshape(-1,96,96,1), y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 with Locally Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define RMSE\n",
    "def rmse (y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "# create model - use random search\n",
    "def create_model(x_train, y_train, n_point):\n",
    "\n",
    "    n_conv_layer = 6\n",
    "    conv_filter1 = 8\n",
    "    conv_filter2 = 32\n",
    "    conv_filter3 = 64\n",
    "    conv_filter4 = 64\n",
    "    conv_filter5 = 64\n",
    "    conv_filter6 = 128\n",
    "    \n",
    "    n_dense_layer = 3\n",
    "    dense_neuron1 = 128\n",
    "    dense_neuron2 = 96\n",
    "    dense_neuron3 = 32\n",
    "     \n",
    "    description = 'ConvLayer-{}-Filter-{}-{}-{}-{}-{}-{}-LC-Y-DenseLayer-{}-Neuron-{}-{}-{}-Activation-PReLU'.format( \\\n",
    "            n_conv_layer, conv_filter1, conv_filter2, conv_filter3, conv_filter4, conv_filter5, conv_filter6, \\\n",
    "            n_dense_layer, dense_neuron1, dense_neuron2, dense_neuron3)\n",
    "    \n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # conv layer 1\n",
    "    model.add(Conv2D(conv_filter1, (3, 3), strides=(1,1), padding='same', \\\n",
    "                     input_shape=(96,96,1), data_format='channels_last'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "    \n",
    "    # conv layer 2\n",
    "    model.add(Conv2D(conv_filter2, (3, 3), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "\n",
    "    # conv layer 3\n",
    "    model.add(Conv2D(conv_filter3, (3, 3), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "        \n",
    "    # lc layer 4\n",
    "    model.add(LocallyConnected2D(conv_filter4, (3, 3), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "            \n",
    "    # lc layer 5\n",
    "    model.add(LocallyConnected2D(conv_filter5, (3, 3), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "\n",
    "    # lc layer 6\n",
    "    model.add(LocallyConnected2D(conv_filter6, (3, 3), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # fully connected layer 1\n",
    "    model.add(Dense(dense_neuron1))\n",
    "    model.add(PReLU())\n",
    "    \n",
    "    # fully connected layer 2\n",
    "    model.add(Dense(dense_neuron2))\n",
    "    model.add(PReLU())\n",
    "        \n",
    "    # fully connected layer 3\n",
    "    model.add(Dense(dense_neuron3))\n",
    "    model.add(PReLU())   \n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(n_point))\n",
    "\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='mean_squared_error', metrics=[rmse], optimizer='adam')\n",
    "\n",
    "    return model, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X = np.load('X.npy')\n",
    "y = np.load('y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "X_model1, y_model1, X_model1_val, y_model1_val = prep_data(X, y, points = [0, 1, 2, 3, 20, 21, 28, 29], val_pct=0)\n",
    "X_model2, y_model2, X_model2_val, y_model2_val = prep_data(X, y, points=[4,5,6,7,8,9,10,11,12,13,14,15,16, \\\n",
    "                                                                         17,18,19,22,23,24,25,26,27], val_pct=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvLayer-6-Filter-8-32-64-96-128-256-LC-Y-DenseLayer-3-Neuron-256-128-96-Activation-PReLU\n",
      "Train on 13300 samples, validate on 700 samples\n",
      "Epoch 1/30\n",
      " - 60s - loss: 76.2056 - rmse: 5.9939 - val_loss: 25.2953 - val_rmse: 5.0122\n",
      "Epoch 2/30\n",
      " - 47s - loss: 16.4057 - rmse: 4.0078 - val_loss: 33.8393 - val_rmse: 5.8081\n",
      "Epoch 3/30\n",
      " - 47s - loss: 10.6988 - rmse: 3.2246 - val_loss: 15.2679 - val_rmse: 3.8821\n",
      "Epoch 4/30\n",
      " - 47s - loss: 8.0427 - rmse: 2.7925 - val_loss: 14.2383 - val_rmse: 3.7484\n",
      "Epoch 5/30\n",
      " - 47s - loss: 6.7731 - rmse: 2.5582 - val_loss: 13.9652 - val_rmse: 3.7141\n",
      "Epoch 6/30\n",
      " - 47s - loss: 5.8511 - rmse: 2.3742 - val_loss: 7.7733 - val_rmse: 2.7370\n",
      "Epoch 7/30\n",
      " - 47s - loss: 5.2839 - rmse: 2.2598 - val_loss: 7.1785 - val_rmse: 2.6200\n",
      "Epoch 8/30\n",
      " - 47s - loss: 4.8136 - rmse: 2.1523 - val_loss: 7.7471 - val_rmse: 2.7382\n",
      "Epoch 9/30\n",
      " - 47s - loss: 4.5278 - rmse: 2.0709 - val_loss: 8.6832 - val_rmse: 2.9113\n",
      "Epoch 10/30\n",
      " - 47s - loss: 3.8447 - rmse: 1.9123 - val_loss: 7.2353 - val_rmse: 2.6458\n",
      "Epoch 11/30\n",
      " - 47s - loss: 3.6078 - rmse: 1.8511 - val_loss: 5.4562 - val_rmse: 2.2686\n",
      "Epoch 12/30\n",
      " - 47s - loss: 3.4211 - rmse: 1.7937 - val_loss: 6.7175 - val_rmse: 2.5465\n",
      "Epoch 13/30\n",
      " - 47s - loss: 3.1057 - rmse: 1.7045 - val_loss: 5.2540 - val_rmse: 2.2282\n",
      "Epoch 14/30\n",
      " - 47s - loss: 2.9786 - rmse: 1.6682 - val_loss: 8.0332 - val_rmse: 2.7902\n",
      "Epoch 15/30\n",
      " - 47s - loss: 2.7322 - rmse: 1.6034 - val_loss: 7.1415 - val_rmse: 2.6316\n",
      "Epoch 16/30\n",
      " - 47s - loss: 2.7016 - rmse: 1.5848 - val_loss: 5.5821 - val_rmse: 2.3103\n",
      "Epoch 17/30\n",
      " - 47s - loss: 2.6444 - rmse: 1.5630 - val_loss: 5.2878 - val_rmse: 2.2367\n",
      "Epoch 18/30\n",
      " - 47s - loss: 2.2161 - rmse: 1.4326 - val_loss: 5.6810 - val_rmse: 2.3355\n",
      "Epoch 19/30\n",
      " - 47s - loss: 2.2550 - rmse: 1.4261 - val_loss: 4.3151 - val_rmse: 2.0022\n",
      "Epoch 20/30\n",
      " - 47s - loss: 2.3338 - rmse: 1.4512 - val_loss: 5.2153 - val_rmse: 2.2251\n",
      "Epoch 21/30\n",
      " - 47s - loss: 2.1609 - rmse: 1.4066 - val_loss: 5.2143 - val_rmse: 2.2329\n",
      "Epoch 22/30\n",
      " - 47s - loss: 2.3220 - rmse: 1.4526 - val_loss: 4.6145 - val_rmse: 2.0726\n",
      "Epoch 23/30\n",
      " - 47s - loss: 1.8916 - rmse: 1.3123 - val_loss: 4.6665 - val_rmse: 2.0881\n",
      "Epoch 24/30\n",
      " - 47s - loss: 1.7615 - rmse: 1.2568 - val_loss: 4.8553 - val_rmse: 2.1410\n",
      "Epoch 25/30\n",
      " - 47s - loss: 1.5519 - rmse: 1.1881 - val_loss: 4.6931 - val_rmse: 2.1074\n",
      "Epoch 26/30\n",
      " - 47s - loss: 1.6759 - rmse: 1.2268 - val_loss: 4.1985 - val_rmse: 1.9778\n",
      "Epoch 27/30\n",
      " - 47s - loss: 1.6698 - rmse: 1.2279 - val_loss: 4.4116 - val_rmse: 2.0361\n",
      "Epoch 28/30\n",
      " - 47s - loss: 1.9429 - rmse: 1.2944 - val_loss: 5.1639 - val_rmse: 2.2100\n",
      "Epoch 29/30\n",
      " - 47s - loss: 1.5408 - rmse: 1.1647 - val_loss: 5.0098 - val_rmse: 2.1843\n",
      "Epoch 30/30\n",
      " - 47s - loss: 1.5234 - rmse: 1.1583 - val_loss: 4.7213 - val_rmse: 2.1094\n",
      "Best validation RMSE: 1.977831540788923\n"
     ]
    }
   ],
   "source": [
    "model, description = create_model(X_model1, y_model1, 8)\n",
    "print(description)\n",
    "\n",
    "# fit model\n",
    "result = model.fit(X_model1, y_model1, batch_size=64, epochs=30, verbose=2, validation_split=0.05)\n",
    "\n",
    "#get the highest validation accuracy of the training epochs\n",
    "validation_RMSE = np.amin(result.history['val_rmse'])\n",
    "print('Best validation RMSE:', validation_RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13300 samples, validate on 700 samples\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "result = model.fit(X_model1, y_model1, batch_size=128, epochs=20, verbose=2, validation_split=0.05)\n",
    "\n",
    "#get the highest validation accuracy of the training epochs\n",
    "validation_RMSE = np.amin(result.history['val_rmse'])\n",
    "print('Best validation RMSE:', validation_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del result\n",
    "del model\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, description = create_model(X_model1, y_model1, 8, 'PReLU')\n",
    "print(description)\n",
    "\n",
    "# fit model\n",
    "result = model.fit(X_model2, y_model2, batch_size=64, epochs=20, verbose=2, validation_split=0.05)\n",
    "\n",
    "#get the highest validation accuracy of the training epochs\n",
    "validation_RMSE = np.amin(result.history['val_rmse'])\n",
    "print('Best validation RMSE:', validation_RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define RMSE\n",
    "def rmse (y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "# create model - use random search\n",
    "def create_model(x_train, y_train, n_point):\n",
    "\n",
    "    n_conv_layer = 6\n",
    "    conv_filter1 = 8\n",
    "    conv_filter2 = 64\n",
    "    conv_filter3 = 96\n",
    "    conv_filter4 = 128\n",
    "    conv_filter5 = 256\n",
    "    conv_filter6 = 324\n",
    "    \n",
    "    n_dense_layer = 3\n",
    "    dense_neuron1 = 256\n",
    "    dense_neuron2 = 96\n",
    "    dense_neuron3 = 64\n",
    "     \n",
    "    description = 'ConvLayer-{}-Filter-{}-{}-{}-{}-{}-{}-LC-N-DenseLayer-{}-Neuron-{}-{}-{}-Activation-PReLU'.format( \\\n",
    "            n_conv_layer, conv_filter1, conv_filter2, conv_filter3, conv_filter4, conv_filter5, conv_filter6, \\\n",
    "            n_dense_layer, dense_neuron1, dense_neuron2, dense_neuron3)\n",
    "    \n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # conv layer 1\n",
    "    model.add(Conv2D(conv_filter1, (3, 3), strides=(1,1), padding='same', \\\n",
    "                     input_shape=(96,96,1), data_format='channels_last'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "    \n",
    "    # conv layer 2\n",
    "    model.add(Conv2D(conv_filter2, (3, 3), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "\n",
    "    # conv layer 3\n",
    "    model.add(Conv2D(conv_filter3, (3, 3), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "        \n",
    "    # conv layer 4\n",
    "    model.add(Conv2D(conv_filter4, (3, 3), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "            \n",
    "    # conv layer 5\n",
    "    model.add(Conv2D(conv_filter5, (3, 3), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "\n",
    "    # conv layer 6\n",
    "    model.add(Conv2D(conv_filter6, (3, 3), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # fully connected layer 1\n",
    "    model.add(Dense(dense_neuron1))\n",
    "    model.add(PReLU())\n",
    "    \n",
    "    # fully connected layer 2\n",
    "    model.add(Dense(dense_neuron2))\n",
    "    model.add(PReLU())\n",
    "        \n",
    "    # fully connected layer 3\n",
    "    model.add(Dense(dense_neuron3))\n",
    "    model.add(PReLU())   \n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(n_point))\n",
    "\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='mean_squared_error', metrics=[rmse], optimizer='adam')\n",
    "\n",
    "    return model, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvLayer-6-Filter-8-64-96-128-256-324-LC-N-DenseLayer-3-Neuron-256-96-64-Activation-PReLU\n",
      "Train on 13300 samples, validate on 700 samples\n",
      "Epoch 1/20\n",
      " - 16s - loss: 127.2125 - rmse: 7.0941 - val_loss: 61.3578 - val_rmse: 7.8253\n",
      "Epoch 2/20\n",
      " - 14s - loss: 11.4598 - rmse: 3.3332 - val_loss: 21.1109 - val_rmse: 4.5802\n",
      "Epoch 3/20\n",
      " - 14s - loss: 8.2392 - rmse: 2.8231 - val_loss: 12.8376 - val_rmse: 3.5523\n",
      "Epoch 4/20\n",
      " - 14s - loss: 6.3533 - rmse: 2.4735 - val_loss: 14.7145 - val_rmse: 3.8157\n",
      "Epoch 5/20\n",
      " - 14s - loss: 5.3996 - rmse: 2.2771 - val_loss: 13.0159 - val_rmse: 3.5854\n",
      "Epoch 6/20\n",
      " - 14s - loss: 4.7822 - rmse: 2.1422 - val_loss: 17.4576 - val_rmse: 4.1563\n",
      "Epoch 7/20\n",
      " - 14s - loss: 4.4293 - rmse: 2.0604 - val_loss: 6.0184 - val_rmse: 2.3872\n",
      "Epoch 8/20\n",
      " - 14s - loss: 3.8953 - rmse: 1.9342 - val_loss: 5.7027 - val_rmse: 2.3209\n",
      "Epoch 9/20\n",
      " - 14s - loss: 3.7031 - rmse: 1.8704 - val_loss: 5.7806 - val_rmse: 2.3353\n",
      "Epoch 10/20\n",
      " - 14s - loss: 3.3118 - rmse: 1.7768 - val_loss: 14.3425 - val_rmse: 3.7672\n",
      "Epoch 11/20\n",
      " - 14s - loss: 2.9792 - rmse: 1.6818 - val_loss: 9.3576 - val_rmse: 3.0240\n",
      "Epoch 12/20\n",
      " - 14s - loss: 2.9780 - rmse: 1.6720 - val_loss: 4.3059 - val_rmse: 1.9929\n",
      "Epoch 13/20\n",
      " - 14s - loss: 2.6825 - rmse: 1.5892 - val_loss: 6.6151 - val_rmse: 2.5166\n",
      "Epoch 14/20\n",
      " - 14s - loss: 2.5855 - rmse: 1.5602 - val_loss: 4.1580 - val_rmse: 1.9488\n",
      "Epoch 15/20\n",
      " - 14s - loss: 2.4362 - rmse: 1.5141 - val_loss: 5.1790 - val_rmse: 2.2184\n",
      "Epoch 16/20\n",
      " - 14s - loss: 2.3995 - rmse: 1.4952 - val_loss: 4.6030 - val_rmse: 2.0745\n",
      "Epoch 17/20\n",
      " - 14s - loss: 1.9967 - rmse: 1.3650 - val_loss: 4.4347 - val_rmse: 2.0363\n",
      "Epoch 18/20\n",
      " - 14s - loss: 1.8035 - rmse: 1.2830 - val_loss: 19.5831 - val_rmse: 4.4161\n",
      "Epoch 19/20\n",
      " - 14s - loss: 1.9857 - rmse: 1.3492 - val_loss: 3.8724 - val_rmse: 1.8827\n",
      "Epoch 20/20\n",
      " - 14s - loss: 2.1484 - rmse: 1.3926 - val_loss: 20.5332 - val_rmse: 4.5186\n",
      "Best validation RMSE: 1.8826921088354929\n"
     ]
    }
   ],
   "source": [
    "model, description = create_model(X_model1, y_model1, 8)\n",
    "print(description)\n",
    "\n",
    "# fit model\n",
    "result = model.fit(X_model1, y_model1, batch_size=64, epochs=20, verbose=2, validation_split=0.05)\n",
    "\n",
    "#get the highest validation accuracy of the training epochs\n",
    "validation_RMSE = np.amin(result.history['val_rmse'])\n",
    "print('Best validation RMSE:', validation_RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13300 samples, validate on 700 samples\n",
      "Epoch 1/20\n",
      " - 13s - loss: 1.6183 - rmse: 1.2232 - val_loss: 3.5878 - val_rmse: 1.8450\n",
      "Epoch 2/20\n",
      " - 13s - loss: 1.2700 - rmse: 1.0758 - val_loss: 8.5349 - val_rmse: 2.9042\n",
      "Epoch 3/20\n",
      " - 13s - loss: 1.0864 - rmse: 0.9897 - val_loss: 15.5250 - val_rmse: 3.9326\n",
      "Epoch 4/20\n",
      " - 13s - loss: 1.0957 - rmse: 0.9913 - val_loss: 3.6496 - val_rmse: 1.8627\n",
      "Epoch 5/20\n",
      " - 13s - loss: 1.0557 - rmse: 0.9647 - val_loss: 6.8592 - val_rmse: 2.6035\n",
      "Epoch 6/20\n",
      " - 13s - loss: 1.0499 - rmse: 0.9702 - val_loss: 25.6027 - val_rmse: 5.0565\n",
      "Epoch 7/20\n",
      " - 13s - loss: 1.0891 - rmse: 0.9927 - val_loss: 4.0972 - val_rmse: 1.9876\n",
      "Epoch 8/20\n",
      " - 13s - loss: 1.0065 - rmse: 0.9381 - val_loss: 14.2987 - val_rmse: 3.7746\n",
      "Epoch 9/20\n",
      " - 13s - loss: 1.0739 - rmse: 0.9761 - val_loss: 43.7463 - val_rmse: 6.6122\n",
      "Epoch 10/20\n",
      " - 13s - loss: 0.9549 - rmse: 0.9095 - val_loss: 3.1366 - val_rmse: 1.7185\n",
      "Epoch 11/20\n",
      " - 13s - loss: 0.9369 - rmse: 0.8994 - val_loss: 38.2023 - val_rmse: 6.1791\n",
      "Epoch 12/20\n",
      " - 13s - loss: 1.1383 - rmse: 1.0079 - val_loss: 8.3024 - val_rmse: 2.8668\n",
      "Epoch 13/20\n",
      " - 13s - loss: 1.1433 - rmse: 1.0016 - val_loss: 6.3777 - val_rmse: 2.5019\n",
      "Epoch 14/20\n",
      " - 13s - loss: 1.0116 - rmse: 0.9430 - val_loss: 22.0386 - val_rmse: 4.6899\n",
      "Epoch 15/20\n",
      " - 13s - loss: 1.3321 - rmse: 1.0881 - val_loss: 3.3919 - val_rmse: 1.7900\n",
      "Epoch 16/20\n",
      " - 13s - loss: 0.8931 - rmse: 0.8765 - val_loss: 3.3753 - val_rmse: 1.7911\n",
      "Epoch 17/20\n",
      " - 13s - loss: 0.9073 - rmse: 0.8832 - val_loss: 13.1689 - val_rmse: 3.6200\n",
      "Epoch 18/20\n",
      " - 13s - loss: 0.9405 - rmse: 0.9069 - val_loss: 4.9917 - val_rmse: 2.2066\n",
      "Epoch 19/20\n",
      " - 13s - loss: 0.9247 - rmse: 0.8933 - val_loss: 3.3447 - val_rmse: 1.7720\n",
      "Epoch 20/20\n",
      " - 13s - loss: 1.0574 - rmse: 0.9617 - val_loss: 5.5882 - val_rmse: 2.3391\n",
      "Best validation RMSE: 1.718524603843689\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "result = model.fit(X_model1, y_model1, batch_size=128, epochs=20, verbose=2, validation_split=0.05)\n",
    "\n",
    "#get the highest validation accuracy of the training epochs\n",
    "validation_RMSE = np.amin(result.history['val_rmse'])\n",
    "print('Best validation RMSE:', validation_RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13300 samples, validate on 700 samples\n",
      "Epoch 1/20\n",
      " - 12s - loss: 0.4537 - rmse: 0.6271 - val_loss: 3.8809 - val_rmse: 1.9480\n",
      "Epoch 2/20\n",
      " - 12s - loss: 0.4101 - rmse: 0.5921 - val_loss: 3.3716 - val_rmse: 1.8056\n",
      "Epoch 3/20\n",
      " - 12s - loss: 0.4320 - rmse: 0.6016 - val_loss: 2.9837 - val_rmse: 1.6902\n",
      "Epoch 4/20\n",
      " - 12s - loss: 0.5640 - rmse: 0.7193 - val_loss: 3.1445 - val_rmse: 1.7450\n",
      "Epoch 5/20\n",
      " - 12s - loss: 0.4810 - rmse: 0.6480 - val_loss: 3.1847 - val_rmse: 1.7500\n",
      "Epoch 6/20\n",
      " - 12s - loss: 0.4025 - rmse: 0.5830 - val_loss: 2.9234 - val_rmse: 1.6763\n",
      "Epoch 7/20\n",
      " - 12s - loss: 0.4373 - rmse: 0.6189 - val_loss: 5.8012 - val_rmse: 2.3979\n",
      "Epoch 8/20\n",
      " - 12s - loss: 0.5165 - rmse: 0.6630 - val_loss: 3.4368 - val_rmse: 1.8289\n",
      "Epoch 9/20\n",
      " - 12s - loss: 0.4375 - rmse: 0.6131 - val_loss: 2.9037 - val_rmse: 1.6672\n",
      "Epoch 10/20\n",
      " - 12s - loss: 0.4122 - rmse: 0.5862 - val_loss: 2.7866 - val_rmse: 1.6316\n",
      "Epoch 11/20\n",
      " - 12s - loss: 0.4244 - rmse: 0.6032 - val_loss: 3.0385 - val_rmse: 1.7067\n",
      "Epoch 12/20\n",
      " - 12s - loss: 0.3935 - rmse: 0.5720 - val_loss: 4.7519 - val_rmse: 2.1591\n",
      "Epoch 13/20\n",
      " - 12s - loss: 0.5471 - rmse: 0.6952 - val_loss: 3.6091 - val_rmse: 1.8706\n",
      "Epoch 14/20\n",
      " - 12s - loss: 0.4527 - rmse: 0.6155 - val_loss: 3.3827 - val_rmse: 1.8078\n",
      "Epoch 15/20\n",
      " - 12s - loss: 0.4400 - rmse: 0.5969 - val_loss: 4.0839 - val_rmse: 1.9962\n",
      "Epoch 16/20\n",
      " - 12s - loss: 0.4274 - rmse: 0.5979 - val_loss: 2.8888 - val_rmse: 1.6652\n",
      "Epoch 17/20\n",
      " - 12s - loss: 0.4436 - rmse: 0.6055 - val_loss: 3.2254 - val_rmse: 1.7623\n",
      "Epoch 18/20\n",
      " - 12s - loss: 0.3591 - rmse: 0.5371 - val_loss: 2.9696 - val_rmse: 1.6899\n",
      "Epoch 19/20\n",
      " - 12s - loss: 0.4651 - rmse: 0.6357 - val_loss: 3.6793 - val_rmse: 1.8905\n",
      "Epoch 20/20\n",
      " - 12s - loss: 0.3850 - rmse: 0.5678 - val_loss: 3.9182 - val_rmse: 1.9521\n",
      "Best validation RMSE: 1.631601164681571\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "result = model.fit(X_model1, y_model1, batch_size=512, epochs=20, verbose=2, validation_split=0.05)\n",
    "\n",
    "#get the highest validation accuracy of the training epochs\n",
    "validation_RMSE = np.amin(result.history['val_rmse'])\n",
    "print('Best validation RMSE:', validation_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('model1_4pts_try2.h5')\n",
    "\n",
    "del result\n",
    "del model\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvLayer-6-Filter-8-64-96-128-256-324-LC-N-DenseLayer-3-Neuron-256-96-64-Activation-PReLU\n",
      "Train on 4094 samples, validate on 216 samples\n",
      "Epoch 1/20\n",
      " - 6s - loss: 268.7913 - rmse: 11.4141 - val_loss: 43.6134 - val_rmse: 6.6018\n",
      "Epoch 2/20\n",
      " - 4s - loss: 15.0408 - rmse: 3.8657 - val_loss: 24.4405 - val_rmse: 4.9417\n",
      "Epoch 3/20\n",
      " - 4s - loss: 11.5847 - rmse: 3.3919 - val_loss: 21.2558 - val_rmse: 4.6062\n",
      "Epoch 4/20\n",
      " - 4s - loss: 8.5489 - rmse: 2.9143 - val_loss: 22.2491 - val_rmse: 4.7144\n",
      "Epoch 5/20\n",
      " - 4s - loss: 6.9431 - rmse: 2.6258 - val_loss: 16.5177 - val_rmse: 4.0610\n",
      "Epoch 6/20\n",
      " - 4s - loss: 6.1373 - rmse: 2.4663 - val_loss: 11.2440 - val_rmse: 3.3495\n",
      "Epoch 7/20\n",
      " - 4s - loss: 5.4151 - rmse: 2.3199 - val_loss: 9.7001 - val_rmse: 3.1107\n",
      "Epoch 8/20\n",
      " - 4s - loss: 5.1197 - rmse: 2.2541 - val_loss: 6.8471 - val_rmse: 2.6133\n",
      "Epoch 9/20\n",
      " - 4s - loss: 4.9189 - rmse: 2.2119 - val_loss: 5.3716 - val_rmse: 2.3140\n",
      "Epoch 10/20\n",
      " - 4s - loss: 4.1296 - rmse: 2.0276 - val_loss: 4.9754 - val_rmse: 2.2264\n",
      "Epoch 11/20\n",
      " - 4s - loss: 4.3431 - rmse: 2.0778 - val_loss: 6.8953 - val_rmse: 2.6233\n",
      "Epoch 12/20\n",
      " - 4s - loss: 3.6955 - rmse: 1.9164 - val_loss: 4.0892 - val_rmse: 2.0179\n",
      "Epoch 13/20\n",
      " - 4s - loss: 3.4148 - rmse: 1.8405 - val_loss: 6.0435 - val_rmse: 2.4551\n",
      "Epoch 14/20\n",
      " - 4s - loss: 3.2514 - rmse: 1.7972 - val_loss: 4.7379 - val_rmse: 2.1747\n",
      "Epoch 15/20\n",
      " - 4s - loss: 2.9088 - rmse: 1.7012 - val_loss: 4.6050 - val_rmse: 2.1441\n",
      "Epoch 16/20\n",
      " - 4s - loss: 2.9982 - rmse: 1.7196 - val_loss: 4.7754 - val_rmse: 2.1811\n",
      "Epoch 17/20\n",
      " - 4s - loss: 2.8125 - rmse: 1.6656 - val_loss: 4.4357 - val_rmse: 2.1035\n",
      "Epoch 18/20\n",
      " - 4s - loss: 2.4275 - rmse: 1.5514 - val_loss: 5.2625 - val_rmse: 2.2929\n",
      "Epoch 19/20\n",
      " - 4s - loss: 2.5887 - rmse: 1.5999 - val_loss: 3.1337 - val_rmse: 1.7693\n",
      "Epoch 20/20\n",
      " - 4s - loss: 2.0675 - rmse: 1.4344 - val_loss: 4.1362 - val_rmse: 2.0334\n",
      "Best validation RMSE: 1.769298721242834\n"
     ]
    }
   ],
   "source": [
    "model, description = create_model(X_model1, y_model1, 22)\n",
    "print(description)\n",
    "\n",
    "# fit model\n",
    "result = model.fit(X_model2, y_model2, batch_size=64, epochs=20, verbose=2, validation_split=0.05)\n",
    "\n",
    "#get the highest validation accuracy of the training epochs\n",
    "validation_RMSE = np.amin(result.history['val_rmse'])\n",
    "print('Best validation RMSE:', validation_RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4094 samples, validate on 216 samples\n",
      "Epoch 1/20\n",
      " - 4s - loss: 1.9526 - rmse: 1.3902 - val_loss: 3.1571 - val_rmse: 1.7767\n",
      "Epoch 2/20\n",
      " - 4s - loss: 1.9819 - rmse: 1.4027 - val_loss: 3.9222 - val_rmse: 1.9804\n",
      "Epoch 3/20\n",
      " - 4s - loss: 1.7261 - rmse: 1.3103 - val_loss: 4.8529 - val_rmse: 2.2029\n",
      "Epoch 4/20\n",
      " - 4s - loss: 1.6497 - rmse: 1.2806 - val_loss: 2.9476 - val_rmse: 1.7166\n",
      "Epoch 5/20\n",
      " - 4s - loss: 1.5294 - rmse: 1.2348 - val_loss: 3.0575 - val_rmse: 1.7484\n",
      "Epoch 6/20\n",
      " - 4s - loss: 1.6861 - rmse: 1.2947 - val_loss: 3.1700 - val_rmse: 1.7800\n",
      "Epoch 7/20\n",
      " - 4s - loss: 1.7148 - rmse: 1.3037 - val_loss: 2.8924 - val_rmse: 1.7007\n",
      "Epoch 8/20\n",
      " - 4s - loss: 1.6029 - rmse: 1.2602 - val_loss: 3.3898 - val_rmse: 1.8411\n",
      "Epoch 9/20\n",
      " - 4s - loss: 1.4674 - rmse: 1.2081 - val_loss: 2.3717 - val_rmse: 1.5400\n",
      "Epoch 10/20\n",
      " - 4s - loss: 1.3057 - rmse: 1.1411 - val_loss: 2.3758 - val_rmse: 1.5413\n",
      "Epoch 11/20\n",
      " - 4s - loss: 1.3394 - rmse: 1.1554 - val_loss: 2.4680 - val_rmse: 1.5709\n",
      "Epoch 12/20\n",
      " - 4s - loss: 1.2429 - rmse: 1.1132 - val_loss: 2.2297 - val_rmse: 1.4932\n",
      "Epoch 13/20\n",
      " - 4s - loss: 1.3199 - rmse: 1.1457 - val_loss: 3.0668 - val_rmse: 1.7512\n",
      "Epoch 14/20\n",
      " - 4s - loss: 1.2966 - rmse: 1.1350 - val_loss: 2.1781 - val_rmse: 1.4758\n",
      "Epoch 15/20\n",
      " - 4s - loss: 1.1341 - rmse: 1.0635 - val_loss: 2.3111 - val_rmse: 1.5202\n",
      "Epoch 16/20\n",
      " - 4s - loss: 1.1452 - rmse: 1.0686 - val_loss: 2.1065 - val_rmse: 1.4513\n",
      "Epoch 17/20\n",
      " - 4s - loss: 1.0866 - rmse: 1.0403 - val_loss: 2.4326 - val_rmse: 1.5597\n",
      "Epoch 18/20\n",
      " - 4s - loss: 1.2451 - rmse: 1.1117 - val_loss: 2.5653 - val_rmse: 1.6016\n",
      "Epoch 19/20\n",
      " - 4s - loss: 1.2625 - rmse: 1.1217 - val_loss: 2.7387 - val_rmse: 1.6547\n",
      "Epoch 20/20\n",
      " - 4s - loss: 1.3377 - rmse: 1.1528 - val_loss: 2.2099 - val_rmse: 1.4866\n",
      "Best validation RMSE: 1.4512881614543773\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "result = model.fit(X_model2, y_model2, batch_size=128, epochs=20, verbose=2, validation_split=0.05)\n",
    "\n",
    "#get the highest validation accuracy of the training epochs\n",
    "validation_RMSE = np.amin(result.history['val_rmse'])\n",
    "print('Best validation RMSE:', validation_RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4094 samples, validate on 216 samples\n",
      "Epoch 1/40\n",
      " - 5s - loss: 1.1966 - rmse: 1.0919 - val_loss: 2.0231 - val_rmse: 1.4224\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.0177 - rmse: 1.0087 - val_loss: 1.8646 - val_rmse: 1.3655\n",
      "Epoch 3/40\n",
      " - 4s - loss: 0.9202 - rmse: 0.9588 - val_loss: 2.2468 - val_rmse: 1.4989\n",
      "Epoch 4/40\n",
      " - 4s - loss: 0.9011 - rmse: 0.9484 - val_loss: 2.5214 - val_rmse: 1.5879\n",
      "Epoch 5/40\n",
      " - 4s - loss: 0.9109 - rmse: 0.9528 - val_loss: 2.8759 - val_rmse: 1.6959\n",
      "Epoch 6/40\n",
      " - 4s - loss: 0.8362 - rmse: 0.9138 - val_loss: 3.0566 - val_rmse: 1.7483\n",
      "Epoch 7/40\n",
      " - 4s - loss: 0.8338 - rmse: 0.9127 - val_loss: 3.1126 - val_rmse: 1.7643\n",
      "Epoch 8/40\n",
      " - 4s - loss: 0.7859 - rmse: 0.8864 - val_loss: 3.0566 - val_rmse: 1.7483\n",
      "Epoch 9/40\n",
      " - 4s - loss: 0.8221 - rmse: 0.9058 - val_loss: 3.0675 - val_rmse: 1.7514\n",
      "Epoch 10/40\n",
      " - 4s - loss: 0.7798 - rmse: 0.8824 - val_loss: 3.5213 - val_rmse: 1.8765\n",
      "Epoch 11/40\n",
      " - 4s - loss: 0.8362 - rmse: 0.9141 - val_loss: 3.3070 - val_rmse: 1.8185\n",
      "Epoch 12/40\n",
      " - 4s - loss: 0.7788 - rmse: 0.8823 - val_loss: 2.9997 - val_rmse: 1.7320\n",
      "Epoch 13/40\n",
      " - 4s - loss: 0.7722 - rmse: 0.8783 - val_loss: 2.2040 - val_rmse: 1.4846\n",
      "Epoch 14/40\n",
      " - 4s - loss: 0.8353 - rmse: 0.9138 - val_loss: 2.2766 - val_rmse: 1.5088\n",
      "Epoch 15/40\n",
      " - 4s - loss: 0.7898 - rmse: 0.8884 - val_loss: 2.6370 - val_rmse: 1.6239\n",
      "Epoch 16/40\n",
      " - 4s - loss: 0.7548 - rmse: 0.8686 - val_loss: 2.8896 - val_rmse: 1.6999\n",
      "Epoch 17/40\n",
      " - 4s - loss: 0.7236 - rmse: 0.8505 - val_loss: 2.4906 - val_rmse: 1.5782\n",
      "Epoch 18/40\n",
      " - 4s - loss: 0.7177 - rmse: 0.8469 - val_loss: 2.1692 - val_rmse: 1.4728\n",
      "Epoch 19/40\n",
      " - 4s - loss: 0.7225 - rmse: 0.8498 - val_loss: 2.7175 - val_rmse: 1.6485\n",
      "Epoch 20/40\n",
      " - 4s - loss: 0.6976 - rmse: 0.8351 - val_loss: 2.5501 - val_rmse: 1.5969\n",
      "Epoch 21/40\n",
      " - 4s - loss: 0.6978 - rmse: 0.8351 - val_loss: 2.5562 - val_rmse: 1.5988\n",
      "Epoch 22/40\n",
      " - 4s - loss: 0.6860 - rmse: 0.8280 - val_loss: 2.7231 - val_rmse: 1.6502\n",
      "Epoch 23/40\n",
      " - 4s - loss: 0.6829 - rmse: 0.8263 - val_loss: 2.9503 - val_rmse: 1.7177\n",
      "Epoch 24/40\n",
      " - 4s - loss: 0.6974 - rmse: 0.8349 - val_loss: 2.5764 - val_rmse: 1.6051\n",
      "Epoch 25/40\n",
      " - 4s - loss: 0.6925 - rmse: 0.8318 - val_loss: 2.3375 - val_rmse: 1.5289\n",
      "Epoch 26/40\n",
      " - 4s - loss: 0.7298 - rmse: 0.8535 - val_loss: 2.8643 - val_rmse: 1.6924\n",
      "Epoch 27/40\n",
      " - 4s - loss: 0.6905 - rmse: 0.8304 - val_loss: 2.3416 - val_rmse: 1.5302\n",
      "Epoch 28/40\n",
      " - 4s - loss: 0.6974 - rmse: 0.8341 - val_loss: 2.1181 - val_rmse: 1.4554\n",
      "Epoch 29/40\n",
      " - 4s - loss: 0.7770 - rmse: 0.8803 - val_loss: 2.4409 - val_rmse: 1.5624\n",
      "Epoch 30/40\n",
      " - 4s - loss: 0.7644 - rmse: 0.8731 - val_loss: 2.7263 - val_rmse: 1.6511\n",
      "Epoch 31/40\n",
      " - 4s - loss: 0.8309 - rmse: 0.9109 - val_loss: 2.5581 - val_rmse: 1.5994\n",
      "Epoch 32/40\n",
      " - 4s - loss: 0.8222 - rmse: 0.9056 - val_loss: 1.9784 - val_rmse: 1.4066\n",
      "Epoch 33/40\n",
      " - 4s - loss: 0.7212 - rmse: 0.8483 - val_loss: 2.0204 - val_rmse: 1.4214\n",
      "Epoch 34/40\n",
      " - 4s - loss: 0.7100 - rmse: 0.8420 - val_loss: 1.9811 - val_rmse: 1.4075\n",
      "Epoch 35/40\n",
      " - 4s - loss: 0.6770 - rmse: 0.8223 - val_loss: 2.1161 - val_rmse: 1.4547\n",
      "Epoch 36/40\n",
      " - 4s - loss: 0.6337 - rmse: 0.7958 - val_loss: 2.2442 - val_rmse: 1.4981\n",
      "Epoch 37/40\n",
      " - 4s - loss: 0.6244 - rmse: 0.7899 - val_loss: 2.4379 - val_rmse: 1.5614\n",
      "Epoch 38/40\n",
      " - 4s - loss: 0.6686 - rmse: 0.8174 - val_loss: 2.5609 - val_rmse: 1.6003\n",
      "Epoch 39/40\n",
      " - 4s - loss: 0.6662 - rmse: 0.8154 - val_loss: 2.5099 - val_rmse: 1.5843\n",
      "Epoch 40/40\n",
      " - 4s - loss: 0.7472 - rmse: 0.8628 - val_loss: 2.9381 - val_rmse: 1.7141\n",
      "Best validation RMSE: 1.3655198812484741\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "result = model.fit(X_model2, y_model2, batch_size=512, epochs=40, verbose=2, validation_split=0.05)\n",
    "\n",
    "#get the highest validation accuracy of the training epochs\n",
    "validation_RMSE = np.amin(result.history['val_rmse'])\n",
    "print('Best validation RMSE:', validation_RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('model2_11pts_try2.h5')\n",
    "\n",
    "del result\n",
    "del model\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define RMSE\n",
    "def rmse (y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "# create model - use random search\n",
    "def create_model(n_point):\n",
    "\n",
    "    n_conv_layer = 6\n",
    "    conv_filter1 = 28\n",
    "    conv_filter2 = 64\n",
    "    conv_filter3 = 64\n",
    "    conv_filter4 = 64\n",
    "    conv_filter5 = 128\n",
    "    conv_filter6 = 128\n",
    "    \n",
    "    n_dense_layer = 3\n",
    "    dense_neuron1 = 256\n",
    "    dense_neuron2 = 96\n",
    "    dense_neuron3 = 64\n",
    "     \n",
    "    description = 'ConvLayer-{}-Filter-{}-{}-{}-{}-{}-{}-LC-N-DenseLayer-{}-Neuron-{}-{}-{}-Activation-PReLU'.format( \\\n",
    "            n_conv_layer, conv_filter1, conv_filter2, conv_filter3, conv_filter4, conv_filter5, conv_filter6, \\\n",
    "            n_dense_layer, dense_neuron1, dense_neuron2, dense_neuron3)\n",
    "    \n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # conv layer 1\n",
    "    model.add(Conv2D(conv_filter1, (3, 3), strides=(1,1), padding='same', \\\n",
    "                     input_shape=(96,96,1), data_format='channels_last'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "    \n",
    "    # conv layer 2\n",
    "    model.add(Conv2D(conv_filter2, (3, 3), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "\n",
    "    # conv layer 3\n",
    "    model.add(Conv2D(conv_filter3, (3, 3), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "        \n",
    "    # conv layer 4\n",
    "    model.add(Conv2D(conv_filter4, (3, 3), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "            \n",
    "    # conv layer 5\n",
    "    model.add(Conv2D(conv_filter5, (3, 3), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "\n",
    "    # conv layer 6\n",
    "    model.add(Conv2D(conv_filter6, (3, 3), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # fully connected layer 1\n",
    "    model.add(Dense(dense_neuron1))\n",
    "    model.add(PReLU())\n",
    "    \n",
    "    # fully connected layer 2\n",
    "    model.add(Dense(dense_neuron2))\n",
    "    model.add(PReLU())\n",
    "        \n",
    "    # fully connected layer 3\n",
    "    model.add(Dense(dense_neuron3))\n",
    "    model.add(PReLU())   \n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(n_point))\n",
    "\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='mean_squared_error', metrics=[rmse], optimizer='adam')\n",
    "\n",
    "    return model, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvLayer-6-Filter-28-64-64-64-128-128-LC-N-DenseLayer-3-Neuron-256-96-64-Activation-PReLU\n",
      "Train on 13300 samples, validate on 700 samples\n",
      "Epoch 1/20\n",
      " - 16s - loss: 178.8321 - rmse: 8.3293 - val_loss: 36.1222 - val_rmse: 6.0020\n",
      "Epoch 2/20\n",
      " - 14s - loss: 13.2840 - rmse: 3.5989 - val_loss: 22.0750 - val_rmse: 4.6842\n",
      "Epoch 3/20\n",
      " - 14s - loss: 9.1611 - rmse: 2.9778 - val_loss: 20.8995 - val_rmse: 4.5554\n",
      "Epoch 4/20\n",
      " - 14s - loss: 7.1707 - rmse: 2.6330 - val_loss: 14.8749 - val_rmse: 3.8386\n",
      "Epoch 5/20\n",
      " - 14s - loss: 6.0294 - rmse: 2.4082 - val_loss: 18.4252 - val_rmse: 4.2784\n",
      "Epoch 6/20\n",
      " - 14s - loss: 5.3828 - rmse: 2.2702 - val_loss: 9.3457 - val_rmse: 3.0191\n",
      "Epoch 7/20\n",
      " - 14s - loss: 4.7527 - rmse: 2.1371 - val_loss: 6.1298 - val_rmse: 2.4073\n",
      "Epoch 8/20\n",
      " - 14s - loss: 4.1697 - rmse: 2.0039 - val_loss: 6.6994 - val_rmse: 2.5338\n",
      "Epoch 9/20\n",
      " - 14s - loss: 4.0364 - rmse: 1.9612 - val_loss: 6.8710 - val_rmse: 2.5559\n",
      "Epoch 10/20\n",
      " - 14s - loss: 3.4850 - rmse: 1.8247 - val_loss: 13.6678 - val_rmse: 3.6820\n",
      "Epoch 11/20\n",
      " - 14s - loss: 3.3767 - rmse: 1.7975 - val_loss: 5.9392 - val_rmse: 2.3751\n",
      "Epoch 12/20\n",
      " - 14s - loss: 3.2372 - rmse: 1.7527 - val_loss: 6.5456 - val_rmse: 2.5062\n",
      "Epoch 13/20\n",
      " - 14s - loss: 2.8743 - rmse: 1.6528 - val_loss: 6.1353 - val_rmse: 2.4169\n",
      "Epoch 14/20\n",
      " - 14s - loss: 2.9492 - rmse: 1.6711 - val_loss: 5.7734 - val_rmse: 2.3392\n",
      "Epoch 15/20\n",
      " - 14s - loss: 2.7226 - rmse: 1.6085 - val_loss: 5.5185 - val_rmse: 2.2890\n",
      "Epoch 16/20\n",
      " - 14s - loss: 2.6229 - rmse: 1.5739 - val_loss: 4.7241 - val_rmse: 2.1057\n",
      "Epoch 17/20\n",
      " - 14s - loss: 2.2955 - rmse: 1.4752 - val_loss: 4.3965 - val_rmse: 2.0124\n",
      "Epoch 18/20\n",
      " - 14s - loss: 2.0214 - rmse: 1.3707 - val_loss: 5.6253 - val_rmse: 2.3163\n",
      "Epoch 19/20\n",
      " - 14s - loss: 2.2330 - rmse: 1.4393 - val_loss: 4.3053 - val_rmse: 2.0028\n",
      "Epoch 20/20\n",
      " - 14s - loss: 2.2433 - rmse: 1.4379 - val_loss: 6.4464 - val_rmse: 2.4890\n",
      "Best validation RMSE: 2.002771305356707\n"
     ]
    }
   ],
   "source": [
    "model, description = create_model(8)\n",
    "print(description)\n",
    "\n",
    "# fit model\n",
    "result = model.fit(X_model1, y_model1, batch_size=64, epochs=20, verbose=2, validation_split=0.05)\n",
    "\n",
    "#get the highest validation accuracy of the training epochs\n",
    "validation_RMSE = np.amin(result.history['val_rmse'])\n",
    "print('Best validation RMSE:', validation_RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13300 samples, validate on 700 samples\n",
      "Epoch 1/20\n",
      " - 14s - loss: 1.7605 - rmse: 1.2915 - val_loss: 3.5416 - val_rmse: 1.8277\n",
      "Epoch 2/20\n",
      " - 13s - loss: 1.4729 - rmse: 1.1731 - val_loss: 3.8034 - val_rmse: 1.9019\n",
      "Epoch 3/20\n",
      " - 13s - loss: 1.2889 - rmse: 1.0957 - val_loss: 11.6742 - val_rmse: 3.4052\n",
      "Epoch 4/20\n",
      " - 13s - loss: 1.3320 - rmse: 1.1098 - val_loss: 5.4884 - val_rmse: 2.3138\n",
      "Epoch 5/20\n",
      " - 13s - loss: 1.4302 - rmse: 1.1419 - val_loss: 7.7478 - val_rmse: 2.7670\n",
      "Epoch 6/20\n",
      " - 13s - loss: 1.3750 - rmse: 1.1327 - val_loss: 3.9291 - val_rmse: 1.9418\n",
      "Epoch 7/20\n",
      " - 13s - loss: 1.3555 - rmse: 1.1192 - val_loss: 3.9104 - val_rmse: 1.9313\n",
      "Epoch 8/20\n",
      " - 13s - loss: 1.2457 - rmse: 1.0648 - val_loss: 17.9951 - val_rmse: 4.2370\n",
      "Epoch 9/20\n",
      " - 13s - loss: 1.3646 - rmse: 1.1203 - val_loss: 11.4973 - val_rmse: 3.3790\n",
      "Epoch 10/20\n",
      " - 13s - loss: 1.3104 - rmse: 1.0954 - val_loss: 3.7333 - val_rmse: 1.8871\n",
      "Epoch 11/20\n",
      " - 13s - loss: 1.1545 - rmse: 1.0207 - val_loss: 37.2141 - val_rmse: 6.0990\n",
      "Epoch 12/20\n",
      " - 13s - loss: 1.2404 - rmse: 1.0631 - val_loss: 9.4954 - val_rmse: 3.0704\n",
      "Epoch 13/20\n",
      " - 13s - loss: 1.2823 - rmse: 1.0826 - val_loss: 6.4285 - val_rmse: 2.5109\n",
      "Epoch 14/20\n",
      " - 13s - loss: 1.2196 - rmse: 1.0489 - val_loss: 6.8161 - val_rmse: 2.5887\n",
      "Epoch 15/20\n",
      " - 13s - loss: 1.3686 - rmse: 1.1251 - val_loss: 4.7267 - val_rmse: 2.1419\n",
      "Epoch 16/20\n",
      " - 13s - loss: 1.0627 - rmse: 0.9758 - val_loss: 3.5278 - val_rmse: 1.8296\n",
      "Epoch 17/20\n",
      " - 13s - loss: 1.1277 - rmse: 1.0102 - val_loss: 15.7440 - val_rmse: 3.9613\n",
      "Epoch 18/20\n",
      " - 13s - loss: 1.0754 - rmse: 0.9819 - val_loss: 4.1637 - val_rmse: 1.9976\n",
      "Epoch 19/20\n",
      " - 13s - loss: 1.0843 - rmse: 0.9860 - val_loss: 3.4337 - val_rmse: 1.8029\n",
      "Epoch 20/20\n",
      " - 13s - loss: 1.1064 - rmse: 0.9972 - val_loss: 4.1915 - val_rmse: 2.0110\n",
      "Best validation RMSE: 1.8029275444575719\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "result = model.fit(X_model1, y_model1, batch_size=128, epochs=20, verbose=2, validation_split=0.05)\n",
    "\n",
    "#get the highest validation accuracy of the training epochs\n",
    "validation_RMSE = np.amin(result.history['val_rmse'])\n",
    "print('Best validation RMSE:', validation_RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13300 samples, validate on 700 samples\n",
      "Epoch 1/40\n",
      " - 14s - loss: 0.7968 - rmse: 0.8687 - val_loss: 3.2706 - val_rmse: 1.7700\n",
      "Epoch 2/40\n",
      " - 12s - loss: 0.6348 - rmse: 0.7675 - val_loss: 3.2183 - val_rmse: 1.7551\n",
      "Epoch 3/40\n",
      " - 12s - loss: 0.6454 - rmse: 0.7684 - val_loss: 3.3428 - val_rmse: 1.7932\n",
      "Epoch 4/40\n",
      " - 12s - loss: 0.6149 - rmse: 0.7461 - val_loss: 3.2385 - val_rmse: 1.7583\n",
      "Epoch 5/40\n",
      " - 12s - loss: 0.6429 - rmse: 0.7733 - val_loss: 3.2967 - val_rmse: 1.7768\n",
      "Epoch 6/40\n",
      " - 12s - loss: 0.5758 - rmse: 0.7263 - val_loss: 3.5561 - val_rmse: 1.8526\n",
      "Epoch 7/40\n",
      " - 12s - loss: 0.5662 - rmse: 0.7076 - val_loss: 3.4257 - val_rmse: 1.8156\n",
      "Epoch 8/40\n",
      " - 12s - loss: 0.5770 - rmse: 0.7296 - val_loss: 4.1471 - val_rmse: 2.0074\n",
      "Epoch 9/40\n",
      " - 12s - loss: 0.5561 - rmse: 0.7116 - val_loss: 3.0775 - val_rmse: 1.7136\n",
      "Epoch 10/40\n",
      " - 12s - loss: 0.5174 - rmse: 0.6794 - val_loss: 3.2231 - val_rmse: 1.7573\n",
      "Epoch 11/40\n",
      " - 12s - loss: 0.5868 - rmse: 0.7355 - val_loss: 3.1886 - val_rmse: 1.7469\n",
      "Epoch 12/40\n",
      " - 12s - loss: 0.6167 - rmse: 0.7540 - val_loss: 3.0978 - val_rmse: 1.7191\n",
      "Epoch 13/40\n",
      " - 12s - loss: 0.5150 - rmse: 0.6804 - val_loss: 3.3824 - val_rmse: 1.8017\n",
      "Epoch 14/40\n",
      " - 12s - loss: 0.5470 - rmse: 0.7011 - val_loss: 7.3705 - val_rmse: 2.7018\n",
      "Epoch 15/40\n",
      " - 12s - loss: 0.5803 - rmse: 0.7301 - val_loss: 3.2746 - val_rmse: 1.7708\n",
      "Epoch 16/40\n",
      " - 12s - loss: 0.5101 - rmse: 0.6691 - val_loss: 3.1175 - val_rmse: 1.7241\n",
      "Epoch 17/40\n",
      " - 12s - loss: 0.5670 - rmse: 0.7185 - val_loss: 3.6068 - val_rmse: 1.8651\n",
      "Epoch 18/40\n",
      " - 12s - loss: 0.5020 - rmse: 0.6729 - val_loss: 3.3301 - val_rmse: 1.7889\n",
      "Epoch 19/40\n",
      " - 12s - loss: 0.5205 - rmse: 0.6853 - val_loss: 3.1322 - val_rmse: 1.7321\n",
      "Epoch 20/40\n",
      " - 12s - loss: 0.6245 - rmse: 0.7567 - val_loss: 3.5677 - val_rmse: 1.8554\n",
      "Epoch 21/40\n",
      " - 12s - loss: 0.5199 - rmse: 0.6770 - val_loss: 3.6588 - val_rmse: 1.8790\n",
      "Epoch 22/40\n",
      " - 12s - loss: 0.6067 - rmse: 0.7345 - val_loss: 3.3157 - val_rmse: 1.7844\n",
      "Epoch 23/40\n",
      " - 12s - loss: 0.5084 - rmse: 0.6765 - val_loss: 3.5563 - val_rmse: 1.8540\n",
      "Epoch 24/40\n",
      " - 12s - loss: 0.4994 - rmse: 0.6591 - val_loss: 3.2976 - val_rmse: 1.7792\n",
      "Epoch 25/40\n",
      " - 12s - loss: 0.5041 - rmse: 0.6720 - val_loss: 3.4212 - val_rmse: 1.8170\n",
      "Epoch 26/40\n",
      " - 12s - loss: 0.4948 - rmse: 0.6631 - val_loss: 3.1212 - val_rmse: 1.7285\n",
      "Epoch 27/40\n",
      " - 12s - loss: 0.4859 - rmse: 0.6440 - val_loss: 3.1395 - val_rmse: 1.7318\n",
      "Epoch 28/40\n",
      " - 12s - loss: 0.5295 - rmse: 0.6744 - val_loss: 4.8653 - val_rmse: 2.1855\n",
      "Epoch 29/40\n",
      " - 12s - loss: 0.4825 - rmse: 0.6591 - val_loss: 3.2617 - val_rmse: 1.7678\n",
      "Epoch 30/40\n",
      " - 12s - loss: 0.5204 - rmse: 0.6726 - val_loss: 3.4092 - val_rmse: 1.8146\n",
      "Epoch 31/40\n",
      " - 12s - loss: 0.6425 - rmse: 0.7682 - val_loss: 3.2453 - val_rmse: 1.7662\n",
      "Epoch 32/40\n",
      " - 12s - loss: 0.5464 - rmse: 0.7015 - val_loss: 3.4496 - val_rmse: 1.8215\n",
      "Epoch 33/40\n",
      " - 12s - loss: 0.4744 - rmse: 0.6437 - val_loss: 5.2438 - val_rmse: 2.2711\n",
      "Epoch 34/40\n",
      " - 12s - loss: 0.4865 - rmse: 0.6530 - val_loss: 3.4910 - val_rmse: 1.8354\n",
      "Epoch 35/40\n",
      " - 12s - loss: 0.4818 - rmse: 0.6507 - val_loss: 5.5327 - val_rmse: 2.3340\n",
      "Epoch 36/40\n",
      " - 12s - loss: 0.5166 - rmse: 0.6754 - val_loss: 3.1474 - val_rmse: 1.7372\n",
      "Epoch 37/40\n",
      " - 12s - loss: 0.5936 - rmse: 0.7386 - val_loss: 5.1557 - val_rmse: 2.2513\n",
      "Epoch 38/40\n",
      " - 12s - loss: 0.4828 - rmse: 0.6511 - val_loss: 3.2782 - val_rmse: 1.7738\n",
      "Epoch 39/40\n",
      " - 12s - loss: 0.5270 - rmse: 0.6864 - val_loss: 5.0224 - val_rmse: 2.2203\n",
      "Epoch 40/40\n",
      " - 12s - loss: 0.4593 - rmse: 0.6345 - val_loss: 4.0133 - val_rmse: 1.9749\n",
      "Best validation RMSE: 1.7135776042938233\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "result = model.fit(X_model1, y_model1, batch_size=512, epochs=40, verbose=2, validation_split=0.05)\n",
    "\n",
    "#get the highest validation accuracy of the training epochs\n",
    "validation_RMSE = np.amin(result.history['val_rmse'])\n",
    "print('Best validation RMSE:', validation_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('model1_4pts_try3.h5')\n",
    "\n",
    "del result\n",
    "del model\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvLayer-6-Filter-28-64-64-64-128-128-LC-N-DenseLayer-3-Neuron-256-96-64-Activation-PReLU\n",
      "Train on 4094 samples, validate on 216 samples\n",
      "Epoch 1/20\n",
      " - 6s - loss: 346.8132 - rmse: 13.2479 - val_loss: 59.2346 - val_rmse: 7.6914\n",
      "Epoch 2/20\n",
      " - 4s - loss: 13.3733 - rmse: 3.6459 - val_loss: 16.1351 - val_rmse: 4.0123\n",
      "Epoch 3/20\n",
      " - 4s - loss: 10.3172 - rmse: 3.1924 - val_loss: 12.8059 - val_rmse: 3.5746\n",
      "Epoch 4/20\n",
      " - 4s - loss: 7.6619 - rmse: 2.7574 - val_loss: 8.3556 - val_rmse: 2.8795\n",
      "Epoch 5/20\n",
      " - 4s - loss: 6.6297 - rmse: 2.5671 - val_loss: 6.4464 - val_rmse: 2.5288\n",
      "Epoch 6/20\n",
      " - 4s - loss: 5.6887 - rmse: 2.3806 - val_loss: 6.9661 - val_rmse: 2.6295\n",
      "Epoch 7/20\n",
      " - 4s - loss: 4.9917 - rmse: 2.2270 - val_loss: 7.2271 - val_rmse: 2.6817\n",
      "Epoch 8/20\n",
      " - 4s - loss: 4.4230 - rmse: 2.0980 - val_loss: 5.6428 - val_rmse: 2.3696\n",
      "Epoch 9/20\n",
      " - 4s - loss: 4.2698 - rmse: 2.0597 - val_loss: 5.2305 - val_rmse: 2.2831\n",
      "Epoch 10/20\n",
      " - 4s - loss: 4.2622 - rmse: 2.0556 - val_loss: 4.5285 - val_rmse: 2.1257\n",
      "Epoch 11/20\n",
      " - 4s - loss: 3.5903 - rmse: 1.8872 - val_loss: 4.4467 - val_rmse: 2.1054\n",
      "Epoch 12/20\n",
      " - 4s - loss: 3.1449 - rmse: 1.7677 - val_loss: 3.8628 - val_rmse: 1.9614\n",
      "Epoch 13/20\n",
      " - 4s - loss: 3.5683 - rmse: 1.8785 - val_loss: 4.4539 - val_rmse: 2.1086\n",
      "Epoch 14/20\n",
      " - 4s - loss: 2.9072 - rmse: 1.6993 - val_loss: 3.4220 - val_rmse: 1.8480\n",
      "Epoch 15/20\n",
      " - 4s - loss: 2.5872 - rmse: 1.6038 - val_loss: 3.6894 - val_rmse: 1.9183\n",
      "Epoch 16/20\n",
      " - 4s - loss: 2.5333 - rmse: 1.5864 - val_loss: 3.5089 - val_rmse: 1.8708\n",
      "Epoch 17/20\n",
      " - 4s - loss: 2.5173 - rmse: 1.5792 - val_loss: 3.1781 - val_rmse: 1.7808\n",
      "Epoch 18/20\n",
      " - 4s - loss: 2.4303 - rmse: 1.5509 - val_loss: 3.8457 - val_rmse: 1.9604\n",
      "Epoch 19/20\n",
      " - 4s - loss: 2.0949 - rmse: 1.4431 - val_loss: 4.2784 - val_rmse: 2.0660\n",
      "Epoch 20/20\n",
      " - 4s - loss: 2.0317 - rmse: 1.4204 - val_loss: 2.8305 - val_rmse: 1.6799\n",
      "Best validation RMSE: 1.6798845617859453\n"
     ]
    }
   ],
   "source": [
    "model, description = create_model(22)\n",
    "print(description)\n",
    "\n",
    "# fit model\n",
    "result = model.fit(X_model2, y_model2, batch_size=64, epochs=20, verbose=2, validation_split=0.05)\n",
    "\n",
    "#get the highest validation accuracy of the training epochs\n",
    "validation_RMSE = np.amin(result.history['val_rmse'])\n",
    "print('Best validation RMSE:', validation_RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4094 samples, validate on 216 samples\n",
      "Epoch 1/20\n",
      " - 4s - loss: 1.8261 - rmse: 1.3487 - val_loss: 2.9409 - val_rmse: 1.7147\n",
      "Epoch 2/20\n",
      " - 4s - loss: 1.7602 - rmse: 1.3248 - val_loss: 4.0355 - val_rmse: 2.0088\n",
      "Epoch 3/20\n",
      " - 4s - loss: 1.6999 - rmse: 1.3006 - val_loss: 3.6356 - val_rmse: 1.9065\n",
      "Epoch 4/20\n",
      " - 4s - loss: 1.5802 - rmse: 1.2541 - val_loss: 2.7702 - val_rmse: 1.6642\n",
      "Epoch 5/20\n",
      " - 4s - loss: 1.5731 - rmse: 1.2515 - val_loss: 2.6142 - val_rmse: 1.6166\n",
      "Epoch 6/20\n",
      " - 4s - loss: 1.6020 - rmse: 1.2624 - val_loss: 2.6184 - val_rmse: 1.6178\n",
      "Epoch 7/20\n",
      " - 4s - loss: 1.3996 - rmse: 1.1817 - val_loss: 2.5499 - val_rmse: 1.5966\n",
      "Epoch 8/20\n",
      " - 4s - loss: 1.4296 - rmse: 1.1943 - val_loss: 3.0127 - val_rmse: 1.7355\n",
      "Epoch 9/20\n",
      " - 4s - loss: 1.3587 - rmse: 1.1645 - val_loss: 2.9858 - val_rmse: 1.7277\n",
      "Epoch 10/20\n",
      " - 4s - loss: 1.3218 - rmse: 1.1483 - val_loss: 2.4274 - val_rmse: 1.5578\n",
      "Epoch 11/20\n",
      " - 4s - loss: 1.3802 - rmse: 1.1722 - val_loss: 2.5641 - val_rmse: 1.6009\n",
      "Epoch 12/20\n",
      " - 4s - loss: 1.2639 - rmse: 1.1226 - val_loss: 2.4614 - val_rmse: 1.5687\n",
      "Epoch 13/20\n",
      " - 4s - loss: 1.3708 - rmse: 1.1667 - val_loss: 3.4240 - val_rmse: 1.8504\n",
      "Epoch 14/20\n",
      " - 4s - loss: 1.3124 - rmse: 1.1431 - val_loss: 2.3093 - val_rmse: 1.5194\n",
      "Epoch 15/20\n",
      " - 4s - loss: 1.2812 - rmse: 1.1284 - val_loss: 2.4679 - val_rmse: 1.5707\n",
      "Epoch 16/20\n",
      " - 4s - loss: 1.2925 - rmse: 1.1336 - val_loss: 2.3626 - val_rmse: 1.5371\n",
      "Epoch 17/20\n",
      " - 4s - loss: 1.2234 - rmse: 1.1050 - val_loss: 2.8005 - val_rmse: 1.6735\n",
      "Epoch 18/20\n",
      " - 4s - loss: 1.5458 - rmse: 1.2360 - val_loss: 2.3983 - val_rmse: 1.5486\n",
      "Epoch 19/20\n",
      " - 4s - loss: 1.4988 - rmse: 1.2144 - val_loss: 2.4174 - val_rmse: 1.5545\n",
      "Epoch 20/20\n",
      " - 4s - loss: 1.6071 - rmse: 1.2613 - val_loss: 2.2546 - val_rmse: 1.5013\n",
      "Best validation RMSE: 1.5013226358978837\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "result = model.fit(X_model2, y_model2, batch_size=128, epochs=20, verbose=2, validation_split=0.05)\n",
    "\n",
    "#get the highest validation accuracy of the training epochs\n",
    "validation_RMSE = np.amin(result.history['val_rmse'])\n",
    "print('Best validation RMSE:', validation_RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4094 samples, validate on 216 samples\n",
      "Epoch 1/40\n",
      " - 5s - loss: 1.4013 - rmse: 1.1793 - val_loss: 2.4199 - val_rmse: 1.5556\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.2083 - rmse: 1.0966 - val_loss: 2.2607 - val_rmse: 1.5036\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.0533 - rmse: 1.0259 - val_loss: 2.0961 - val_rmse: 1.4478\n",
      "Epoch 4/40\n",
      " - 4s - loss: 0.9841 - rmse: 0.9916 - val_loss: 2.1005 - val_rmse: 1.4493\n",
      "Epoch 5/40\n",
      " - 4s - loss: 0.9405 - rmse: 0.9697 - val_loss: 2.0947 - val_rmse: 1.4473\n",
      "Epoch 6/40\n",
      " - 4s - loss: 0.9298 - rmse: 0.9638 - val_loss: 2.2340 - val_rmse: 1.4946\n",
      "Epoch 7/40\n",
      " - 4s - loss: 0.9206 - rmse: 0.9593 - val_loss: 2.2395 - val_rmse: 1.4965\n",
      "Epoch 8/40\n",
      " - 4s - loss: 0.8936 - rmse: 0.9452 - val_loss: 2.4103 - val_rmse: 1.5525\n",
      "Epoch 9/40\n",
      " - 4s - loss: 0.9263 - rmse: 0.9620 - val_loss: 2.6860 - val_rmse: 1.6389\n",
      "Epoch 10/40\n",
      " - 4s - loss: 0.9003 - rmse: 0.9481 - val_loss: 2.6379 - val_rmse: 1.6241\n",
      "Epoch 11/40\n",
      " - 4s - loss: 0.8827 - rmse: 0.9394 - val_loss: 2.6381 - val_rmse: 1.6242\n",
      "Epoch 12/40\n",
      " - 4s - loss: 0.8904 - rmse: 0.9434 - val_loss: 2.5260 - val_rmse: 1.5893\n",
      "Epoch 13/40\n",
      " - 4s - loss: 0.8912 - rmse: 0.9436 - val_loss: 2.2389 - val_rmse: 1.4963\n",
      "Epoch 14/40\n",
      " - 4s - loss: 0.9360 - rmse: 0.9670 - val_loss: 2.3434 - val_rmse: 1.5308\n",
      "Epoch 15/40\n",
      " - 4s - loss: 0.8758 - rmse: 0.9356 - val_loss: 2.7007 - val_rmse: 1.6434\n",
      "Epoch 16/40\n",
      " - 4s - loss: 0.8682 - rmse: 0.9317 - val_loss: 2.8803 - val_rmse: 1.6972\n",
      "Epoch 17/40\n",
      " - 4s - loss: 0.8762 - rmse: 0.9356 - val_loss: 2.6594 - val_rmse: 1.6308\n",
      "Epoch 18/40\n",
      " - 4s - loss: 0.8579 - rmse: 0.9260 - val_loss: 2.2360 - val_rmse: 1.4953\n",
      "Epoch 19/40\n",
      " - 4s - loss: 0.8732 - rmse: 0.9343 - val_loss: 2.4417 - val_rmse: 1.5626\n",
      "Epoch 20/40\n",
      " - 4s - loss: 0.8344 - rmse: 0.9132 - val_loss: 2.6657 - val_rmse: 1.6327\n",
      "Epoch 21/40\n",
      " - 4s - loss: 0.8427 - rmse: 0.9177 - val_loss: 2.2648 - val_rmse: 1.5049\n",
      "Epoch 22/40\n",
      " - 4s - loss: 0.8230 - rmse: 0.9068 - val_loss: 2.8369 - val_rmse: 1.6843\n",
      "Epoch 23/40\n",
      " - 4s - loss: 0.8214 - rmse: 0.9061 - val_loss: 2.8411 - val_rmse: 1.6856\n",
      "Epoch 24/40\n",
      " - 4s - loss: 0.8339 - rmse: 0.9126 - val_loss: 2.5420 - val_rmse: 1.5944\n",
      "Epoch 25/40\n",
      " - 4s - loss: 0.8387 - rmse: 0.9152 - val_loss: 2.1922 - val_rmse: 1.4806\n",
      "Epoch 26/40\n",
      " - 4s - loss: 0.8738 - rmse: 0.9337 - val_loss: 2.5668 - val_rmse: 1.6021\n",
      "Epoch 27/40\n",
      " - 4s - loss: 0.8233 - rmse: 0.9070 - val_loss: 2.3592 - val_rmse: 1.5360\n",
      "Epoch 28/40\n",
      " - 4s - loss: 0.8651 - rmse: 0.9279 - val_loss: 2.0873 - val_rmse: 1.4448\n",
      "Epoch 29/40\n",
      " - 4s - loss: 0.9290 - rmse: 0.9618 - val_loss: 2.1132 - val_rmse: 1.4537\n",
      "Epoch 30/40\n",
      " - 4s - loss: 0.8393 - rmse: 0.9159 - val_loss: 2.3300 - val_rmse: 1.5264\n",
      "Epoch 31/40\n",
      " - 4s - loss: 0.8195 - rmse: 0.9050 - val_loss: 2.8638 - val_rmse: 1.6923\n",
      "Epoch 32/40\n",
      " - 4s - loss: 0.8717 - rmse: 0.9319 - val_loss: 2.5084 - val_rmse: 1.5838\n",
      "Epoch 33/40\n",
      " - 4s - loss: 0.7863 - rmse: 0.8860 - val_loss: 2.9260 - val_rmse: 1.7106\n",
      "Epoch 34/40\n",
      " - 4s - loss: 0.7941 - rmse: 0.8904 - val_loss: 2.5963 - val_rmse: 1.6113\n",
      "Epoch 35/40\n",
      " - 4s - loss: 0.7665 - rmse: 0.8752 - val_loss: 2.6454 - val_rmse: 1.6265\n",
      "Epoch 36/40\n",
      " - 4s - loss: 0.7658 - rmse: 0.8747 - val_loss: 2.4994 - val_rmse: 1.5809\n",
      "Epoch 37/40\n",
      " - 4s - loss: 0.7600 - rmse: 0.8715 - val_loss: 2.3226 - val_rmse: 1.5240\n",
      "Epoch 38/40\n",
      " - 4s - loss: 0.7702 - rmse: 0.8773 - val_loss: 2.2020 - val_rmse: 1.4839\n",
      "Epoch 39/40\n",
      " - 4s - loss: 0.7969 - rmse: 0.8915 - val_loss: 2.5353 - val_rmse: 1.5923\n",
      "Epoch 40/40\n",
      " - 4s - loss: 0.8122 - rmse: 0.9001 - val_loss: 3.0820 - val_rmse: 1.7556\n",
      "Best validation RMSE: 1.444752812385559\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "result = model.fit(X_model2, y_model2, batch_size=512, epochs=40, verbose=2, validation_split=0.05)\n",
    "\n",
    "#get the highest validation accuracy of the training epochs\n",
    "validation_RMSE = np.amin(result.history['val_rmse'])\n",
    "print('Best validation RMSE:', validation_RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('model2_11pts_try3.h5')\n",
    "\n",
    "del result\n",
    "del model\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Test Data and Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1783, 2)\n",
      "(27124, 4)\n",
      "(27124, 2)\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "training = pd.read_csv(\"all/training.csv\")\n",
    "test = pd.read_csv('all/test.csv')\n",
    "lookup = pd.read_csv('all/IdLookupTable.csv')\n",
    "sample_submission = pd.read_csv('all/SampleSubmission.csv')\n",
    "print(test.shape)\n",
    "print(lookup.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1783, 96, 96, 1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split out image values\n",
    "image = []\n",
    "for i in range(test.shape[0]):\n",
    "    img = test['Image'][i].split(' ')\n",
    "    img = ['0' if j == '' else j for j in img]\n",
    "    image.append(img)\n",
    "    \n",
    "X_test = np.array(image, dtype = 'float').reshape(-1,96,96,1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2\n",
    "# load models\n",
    "model1 = load_model('model1_4pts_try2.h5', custom_objects={'rmse': rmse})\n",
    "model2 = load_model('model2_11pts_try2.h5', custom_objects={'rmse': rmse})\n",
    "\n",
    "# make prediction on test set\n",
    "y_test_model1 = model1.predict(X_test, batch_size=None, verbose=0, steps=None)\n",
    "y_test_model2 = model2.predict(X_test, batch_size=None, verbose=0, steps=None)\n",
    "\n",
    "# combine outputs from 2 models\n",
    "pts1 = [0,1,2,3,20,21,28,29]\n",
    "pts2 = [4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,22,23,24,25,26,27]\n",
    "y_test = np.zeros((1783,30), dtype=np.float64)\n",
    "y_test[:, pts1] = y_test_model1\n",
    "y_test[:, pts2] = y_test_model2\n",
    "\n",
    "# prepare submission\n",
    "submission0 = pd.DataFrame(y_test, columns=training.columns[:-1])\n",
    "submission1 = pd.concat([test['ImageId'], submission0], axis=1)\n",
    "submission2 = pd.melt(submission1, id_vars=['ImageId'], value_vars=training.columns[:-1]).rename \\\n",
    "    (columns={\"variable\": \"FeatureName\", \"value\": \"Location\"})\n",
    "submission3 = pd.merge(lookup.drop(columns=['Location']), submission2, on=['ImageId','FeatureName'], how='left')\n",
    "submission4 = submission3[['RowId', 'Location']]\n",
    "submission4['Location'][submission4['Location']>96]=96\n",
    "submission4.to_csv('submission_2.csv', index=False)\n",
    "print(submission4.shape)\n",
    "submission4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Filabuster\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27124, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowId</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>67.125801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>38.217121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>29.540987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37.156696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60.071815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowId   Location\n",
       "0      1  67.125801\n",
       "1      2  38.217121\n",
       "2      3  29.540987\n",
       "3      4  37.156696\n",
       "4      5  60.071815"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 3\n",
    "# load models\n",
    "model1 = load_model('model1_4pts_try3.h5', custom_objects={'rmse': rmse})\n",
    "model2 = load_model('model2_11pts_try3.h5', custom_objects={'rmse': rmse})\n",
    "\n",
    "# make prediction on test set\n",
    "y_test_model1 = model1.predict(X_test, batch_size=None, verbose=0, steps=None)\n",
    "y_test_model2 = model2.predict(X_test, batch_size=None, verbose=0, steps=None)\n",
    "\n",
    "# combine outputs from 2 models\n",
    "pts1 = [0,1,2,3,20,21,28,29]\n",
    "pts2 = [4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,22,23,24,25,26,27]\n",
    "y_test = np.zeros((1783,30), dtype=np.float64)\n",
    "y_test[:, pts1] = y_test_model1\n",
    "y_test[:, pts2] = y_test_model2\n",
    "\n",
    "# prepare submission\n",
    "submission0 = pd.DataFrame(y_test, columns=training.columns[:-1])\n",
    "submission1 = pd.concat([test['ImageId'], submission0], axis=1)\n",
    "submission2 = pd.melt(submission1, id_vars=['ImageId'], value_vars=training.columns[:-1]).rename \\\n",
    "    (columns={\"variable\": \"FeatureName\", \"value\": \"Location\"})\n",
    "submission3 = pd.merge(lookup.drop(columns=['Location']), submission2, on=['ImageId','FeatureName'], how='left')\n",
    "submission4 = submission3[['RowId', 'Location']]\n",
    "submission4['Location'][submission4['Location']>96]=96\n",
    "submission4.to_csv('submission_3.csv', index=False)\n",
    "print(submission4.shape)\n",
    "submission4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission1 = pd.read_csv(\"submission.csv\")\n",
    "submission2 = pd.read_csv(\"submission_2.csv\")\n",
    "submission3 = pd.read_csv(\"submission_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowId</th>\n",
       "      <th>Location_x</th>\n",
       "      <th>Location_y</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>67.415268</td>\n",
       "      <td>68.196732</td>\n",
       "      <td>67.125801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>38.005962</td>\n",
       "      <td>38.641598</td>\n",
       "      <td>38.217121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>29.572035</td>\n",
       "      <td>30.426266</td>\n",
       "      <td>29.540987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>36.070862</td>\n",
       "      <td>36.990479</td>\n",
       "      <td>37.156696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60.440517</td>\n",
       "      <td>58.371372</td>\n",
       "      <td>60.071815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowId  Location_x  Location_y   Location\n",
       "0      1   67.415268   68.196732  67.125801\n",
       "1      2   38.005962   38.641598  38.217121\n",
       "2      3   29.572035   30.426266  29.540987\n",
       "3      4   36.070862   36.990479  37.156696\n",
       "4      5   60.440517   58.371372  60.071815"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble0 = pd.merge(submission1, submission2, on=['RowId'], how='inner')\n",
    "ensemble = pd.merge(ensemble0, submission3, on=['RowId'], how='inner')\n",
    "ensemble.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble['Location'] = ensemble[['Location_x', 'Location_y', 'Location']].mean(axis=1)\n",
    "ensemble.drop(columns=['Location_x', 'Location_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowId</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>67.730422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>38.311929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>29.948243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>36.600229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>59.479930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowId   Location\n",
       "0      1  67.730422\n",
       "1      2  38.311929\n",
       "2      3  29.948243\n",
       "3      4  36.600229\n",
       "4      5  59.479930"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.to_csv('submission_ensemble2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
