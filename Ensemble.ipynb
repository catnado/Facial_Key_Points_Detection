{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(123)  # for reproducibility\n",
    " \n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, LeakyReLU, PReLU, LocallyConnected2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy.ndimage import rotate\n",
    "\n",
    "from random import uniform\n",
    "from numpy.random import choice\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from randomized_relu import randomized_relu\n",
    "from drop_activation import drop_activation\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "get_custom_objects().update({'randomized_relu': Activation(randomized_relu)})\n",
    "get_custom_objects().update({'drop_activation': Activation(drop_activation)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mirror functions\n",
    "def mirror_X(input_X):\n",
    "    return input_X.reshape(-1,96,96)[:, :, list(range(95, -1, -1))].reshape(-1, 96*96)\n",
    "    \n",
    "def mirror_y(input_y, n_point):\n",
    "    output_y = input_y.copy()\n",
    "    # y coordinate stays the same, x coordinate is 96-x\n",
    "    output_y[:,list(range(0,n_point-1,2))] = 95 - input_y[:,list(range(0,n_point-1,2))]\n",
    "    return output_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mirror function to transform X\n",
    "def rotate_X(input_X, degree):\n",
    "    \n",
    "    # create an array of the same size\n",
    "    output_X = np.zeros((input_X.shape), dtype=np.float64)\n",
    "    \n",
    "    # for each image, use sklearn's rotate function to rotate image\n",
    "    # this somehow changes pixel values, cap value between 0 and 255\n",
    "    for i in range(output_X.shape[0]):\n",
    "        output_X[i] = np.clip(rotate(input_X.reshape(-1,96,96)[i], degree, reshape=False, mode='constant', \\\n",
    "                                       cval=150).reshape(96*96), 0, 255)  \n",
    "    return output_X\n",
    "        \n",
    "    \n",
    "# mirror function to transform y\n",
    "def rotate_y(input_y, degree, n_point):\n",
    "    \n",
    "    # create an array of same size\n",
    "    output_y = np.zeros((input_y.shape), dtype=np.float64)\n",
    "    \n",
    "    # define rotation angle and center of rotation\n",
    "    theta = np.radians(degree)\n",
    "    center_x = 95/2\n",
    "    center_y = 95/2\n",
    "\n",
    "    for i in range(output_y.shape[0]):\n",
    "        \n",
    "        # obtain x and y coordinates from dataset\n",
    "        x = input_y[i][np.arange(0,n_point-1,2)]\n",
    "        y = input_y[i][np.arange(1,n_point,2)]\n",
    "        \n",
    "        # use rotation matrix to rotate coordinates around center\n",
    "        x2 = np.cos(theta) * (x - center_x) + np.sin(theta) * (y - center_y) + center_x\n",
    "        y2 = -np.sin(theta) * (x - center_x) + np.cos(theta) * (y - center_y) + center_y\n",
    "        \n",
    "        # put x and y back in original shape\n",
    "        output_y[i] = np.vstack((x2,y2)).transpose().flatten()\n",
    "        \n",
    "    return output_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function - only need to transform X\n",
    "def reduce_contrast(input_X, weight):\n",
    "    return (weight * input_X) + (1 - weight) * input_X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data\n",
    "def prep_data(X, y, points, val_pct):\n",
    "    \n",
    "    # model with specific points \n",
    "    y_model = y[:, points]\n",
    "\n",
    "    # get index of non-missing labels\n",
    "    index = ~np.isnan(y_model).any(axis=1)\n",
    "\n",
    "    # filter out missing labels on training and validation data\n",
    "    X_model = X[index]\n",
    "    y_model = y_model[index]\n",
    "    \n",
    "    # create training and validation set (80/20 split)\n",
    "    X_train, X_val = X_model[:int(X_model.shape[0]*(1-val_pct))], X_model[int(X_model.shape[0]*(1-val_pct)):]\n",
    "    y_train, y_val = y_model[:int(X_model.shape[0]*(1-val_pct))], y_model[int(X_model.shape[0]*(1-val_pct)):]\n",
    "\n",
    "    # training data transformation\n",
    "    degree1 = -10\n",
    "    degree2 = 10\n",
    "    n_point = len(points)\n",
    "    percent = 0.9\n",
    "\n",
    "    X_rotated = np.zeros((X_train.shape), dtype=np.float64)\n",
    "    X_rotated[range(0, len(X_train), 2)] = rotate_X(X_train[range(0, len(X_train), 2)], degree1)\n",
    "    X_rotated[range(1, len(X_train), 2)] = rotate_X(X_train[range(1, len(X_train), 2)], degree2)\n",
    "\n",
    "    y_rotated = np.zeros((y_train.shape), dtype=np.float64)\n",
    "    y_rotated[range(0, len(y_train), 2)] = rotate_y(y_train[range(0, len(y_train), 2)], degree1, n_point)\n",
    "    y_rotated[range(1, len(y_train), 2)] = rotate_y(y_train[range(1, len(y_train), 2)], degree2, n_point)   \n",
    "\n",
    "    X_rotated = np.concatenate((X_train, X_rotated), axis=0)\n",
    "    y_rotated = np.concatenate((y_train, y_rotated), axis=0)\n",
    "    \n",
    "    X_contrast = X_rotated.copy()\n",
    "    X_contrast[range(1, len(X_rotated), 2)] = reduce_contrast(X_rotated[range(1, len(X_rotated), 2)], percent)\n",
    "    \n",
    "    return X_contrast.reshape(-1,96,96,1), y_rotated, X_val.reshape(-1,96,96,1), y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 with Locally Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define RMSE\n",
    "def rmse (y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "# create model - use random search\n",
    "def create_model(x_train, y_train, n_point):\n",
    "\n",
    "    n_conv_layer = 6\n",
    "    conv_filter1 = 8\n",
    "    conv_filter2 = 32\n",
    "    conv_filter3 = 64\n",
    "    conv_filter4 = 96\n",
    "    conv_filter5 = 128\n",
    "    conv_filter6 = 256\n",
    "    \n",
    "    n_dense_layer = 3\n",
    "    dense_neuron1 = 256\n",
    "    dense_neuron2 = 128\n",
    "    dense_neuron3 = 96\n",
    "     \n",
    "    description = 'ConvLayer-{}-Filter-{}-{}-{}-{}-{}-{}-LC-Y-DenseLayer-{}-Neuron-{}-{}-{}-Activation-PReLU'.format( \\\n",
    "            n_conv_layer, conv_filter1, conv_filter2, conv_filter3, conv_filter4, conv_filter5, conv_filter6, \\\n",
    "            n_dense_layer, dense_neuron1, dense_neuron2, dense_neuron3)\n",
    "    \n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # conv layer 1\n",
    "    model.add(Conv2D(conv_filter1, (3, 3), strides=(1,1), padding='same', \\\n",
    "                     input_shape=(96,96,1), data_format='channels_last'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "    \n",
    "    # conv layer 2\n",
    "    model.add(Conv2D(conv_filter2, (3, 3), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "\n",
    "    # conv layer 3\n",
    "    model.add(Conv2D(conv_filter3, (3, 3), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "        \n",
    "    # lc layer 4\n",
    "    model.add(LocallyConnected2D(conv_filter4, (3, 3), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "            \n",
    "    # lc layer 5\n",
    "    model.add(LocallyConnected2D(conv_filter5, (3, 3), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "\n",
    "    # lc layer 6\n",
    "    model.add(LocallyConnected2D(conv_filter6, (3, 3), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # fully connected layer 1\n",
    "    model.add(Dense(dense_neuron1))\n",
    "    model.add(PReLU())\n",
    "    \n",
    "    # fully connected layer 2\n",
    "    model.add(Dense(dense_neuron2))\n",
    "    model.add(PReLU())\n",
    "        \n",
    "    # fully connected layer 3\n",
    "    model.add(Dense(dense_neuron3))\n",
    "    model.add(PReLU())   \n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(n_point))\n",
    "\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='mean_squared_error', metrics=[rmse], optimizer='adam')\n",
    "\n",
    "    return model, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X = np.load('X.npy')\n",
    "y = np.load('y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "X_model1, y_model1, X_model1_val, y_model1_val = prep_data(X, y, points = [0, 1, 2, 3, 20, 21, 28, 29], val_pct=0)\n",
    "X_model2, y_model2, X_model2_val, y_model2_val = prep_data(X, y, points=[4,5,6,7,8,9,10,11,12,13,14,15,16, \\\n",
    "                                                                         17,18,19,22,23,24,25,26,27], val_pct=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, description = create_model(X_model1, y_model1, 8, 'PReLU')\n",
    "print(description)\n",
    "\n",
    "# fit model\n",
    "result = model.fit(X_model1, y_model1, batch_size=64, epochs=20, verbose=2, validation_split=0.05)\n",
    "\n",
    "#get the highest validation accuracy of the training epochs\n",
    "validation_RMSE = np.amin(result.history['val_rmse'])\n",
    "print('Best validation RMSE:', validation_RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, description = create_model(X_model1, y_model1, 8, 'PReLU')\n",
    "print(description)\n",
    "\n",
    "# fit model\n",
    "result = model.fit(X_model2, y_model2, batch_size=64, epochs=20, verbose=2, validation_split=0.05)\n",
    "\n",
    "#get the highest validation accuracy of the training epochs\n",
    "validation_RMSE = np.amin(result.history['val_rmse'])\n",
    "print('Best validation RMSE:', validation_RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define RMSE\n",
    "def rmse (y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "# create model - use random search\n",
    "def create_model(x_train, y_train, n_point):\n",
    "\n",
    "    n_conv_layer = 6\n",
    "    conv_filter1 = 8\n",
    "    conv_filter2 = 64\n",
    "    conv_filter3 = 96\n",
    "    conv_filter4 = 128\n",
    "    conv_filter5 = 256\n",
    "    conv_filter6 = 324\n",
    "    \n",
    "    n_dense_layer = 3\n",
    "    dense_neuron1 = 256\n",
    "    dense_neuron2 = 96\n",
    "    dense_neuron3 = 64\n",
    "     \n",
    "    description = 'ConvLayer-{}-Filter-{}-{}-{}-{}-{}-{}-LC-N-DenseLayer-{}-Neuron-{}-{}-{}-Activation-PReLU'.format( \\\n",
    "            n_conv_layer, conv_filter1, conv_filter2, conv_filter3, conv_filter4, conv_filter5, conv_filter6, \\\n",
    "            n_dense_layer, dense_neuron1, dense_neuron2, dense_neuron3)\n",
    "    \n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # conv layer 1\n",
    "    model.add(Conv2D(conv_filter1, (3, 3), strides=(1,1), padding='same', \\\n",
    "                     input_shape=(96,96,1), data_format='channels_last'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "    \n",
    "    # conv layer 2\n",
    "    model.add(Conv2D(conv_filter2, (3, 3), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "\n",
    "    # conv layer 3\n",
    "    model.add(Conv2D(conv_filter3, (3, 3), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "        \n",
    "    # conv layer 4\n",
    "    model.add(Conv2D(conv_filter4, (3, 3), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "            \n",
    "    # conv layer 5\n",
    "    model.add(Conv2D(conv_filter5, (3, 3), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "\n",
    "    # conv layer 6\n",
    "    model.add(Conv2D(conv_filter6, (3, 3), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # fully connected layer 1\n",
    "    model.add(Dense(dense_neuron1))\n",
    "    model.add(PReLU())\n",
    "    \n",
    "    # fully connected layer 2\n",
    "    model.add(Dense(dense_neuron2))\n",
    "    model.add(PReLU())\n",
    "        \n",
    "    # fully connected layer 3\n",
    "    model.add(Dense(dense_neuron3))\n",
    "    model.add(PReLU())   \n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(n_point))\n",
    "\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='mean_squared_error', metrics=[rmse], optimizer='adam')\n",
    "\n",
    "    return model, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, description = create_model(X_model1, y_model1, 8, 'PReLU')\n",
    "print(description)\n",
    "\n",
    "# fit model\n",
    "result = model.fit(X_model1, y_model1, batch_size=64, epochs=20, verbose=2, validation_split=0.05)\n",
    "\n",
    "#get the highest validation accuracy of the training epochs\n",
    "validation_RMSE = np.amin(result.history['val_rmse'])\n",
    "print('Best validation RMSE:', validation_RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, description = create_model(X_model1, y_model1, 8, 'PReLU')\n",
    "print(description)\n",
    "\n",
    "# fit model\n",
    "result = model.fit(X_model2, y_model2, batch_size=64, epochs=20, verbose=2, validation_split=0.05)\n",
    "\n",
    "#get the highest validation accuracy of the training epochs\n",
    "validation_RMSE = np.amin(result.history['val_rmse'])\n",
    "print('Best validation RMSE:', validation_RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define RMSE\n",
    "def rmse (y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "# create model - use random search\n",
    "def create_model(x_train, y_train, n_point):\n",
    "\n",
    "    n_conv_layer = 8\n",
    "    conv_filter1 = 28\n",
    "    conv_filter2 = 64\n",
    "    conv_filter3 = 64\n",
    "    conv_filter4 = 64\n",
    "    conv_filter5 = 128\n",
    "    conv_filter6 = 128\n",
    "    conv_filter7 = 256\n",
    "    conv_filter8 = 256\n",
    "    \n",
    "    n_dense_layer = 3\n",
    "    dense_neuron1 = 256\n",
    "    dense_neuron2 = 96\n",
    "    dense_neuron3 = 64\n",
    "     \n",
    "    description = 'ConvLayer-{}-Filter-{}-{}-{}-{}-{}-{}-{}-{}-LC-N-DenseLayer-{}-Neuron-{}-{}-{}-Activation-PReLU'.format( \\\n",
    "            n_conv_layer, conv_filter1, conv_filter2, conv_filter3, conv_filter4, conv_filter5, conv_filter6, conv_filter7, conv_filter8, \\\n",
    "            n_dense_layer, dense_neuron1, dense_neuron2, dense_neuron3)\n",
    "    \n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # conv layer 1\n",
    "    model.add(Conv2D(conv_filter1, (3, 3), strides=(1,1), padding='same', \\\n",
    "                     input_shape=(96,96,1), data_format='channels_last'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "    \n",
    "    # conv layer 2\n",
    "    model.add(Conv2D(conv_filter2, (3, 3), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "\n",
    "    # conv layer 3\n",
    "    model.add(Conv2D(conv_filter3, (3, 3), strides=(1,1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "        \n",
    "    # conv layer 4\n",
    "    model.add(LocallyConnected2D(conv_filter4, (3, 3), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "            \n",
    "    # conv layer 5\n",
    "    model.add(LocallyConnected2D(conv_filter5, (3, 3), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "\n",
    "    # conv layer 6\n",
    "    model.add(LocallyConnected2D(conv_filter6, (3, 3), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    \n",
    "    # conv layer 7\n",
    "    model.add(LocallyConnected2D(conv_filter7, (3, 3), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    \n",
    "    # conv layer 8\n",
    "    model.add(LocallyConnected2D(conv_filter8, (3, 3), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # fully connected layer 1\n",
    "    model.add(Dense(dense_neuron1))\n",
    "    model.add(PReLU())\n",
    "    \n",
    "    # fully connected layer 2\n",
    "    model.add(Dense(dense_neuron2))\n",
    "    model.add(PReLU())\n",
    "        \n",
    "    # fully connected layer 3\n",
    "    model.add(Dense(dense_neuron3))\n",
    "    model.add(PReLU())   \n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(n_point))\n",
    "\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='mean_squared_error', metrics=[rmse], optimizer='adam')\n",
    "\n",
    "    return model, description"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
